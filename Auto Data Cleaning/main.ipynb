{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac798078-8bd1-4f41-93ad-ec17e0701287",
   "metadata": {},
   "source": [
    "# Python Automation Project -- Data Cleaning App"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2a763e-3555-4ce7-b15a-4da466b722c6",
   "metadata": {},
   "source": [
    "## This is a Data Cleaning Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc00c33-8c59-4a3d-a82a-b985090f0c57",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Please create a python application that can take datasets and clean the data\n",
    "- It should ask for datasets path and name\n",
    "- it should check number of duplicats and remove all the duplicates \n",
    "- it should keep a copy of all the duplicates\n",
    "- it should check for missing values \n",
    "- if any column that is numeric it should replace nulls with mean else it should drop that rows\n",
    "- at end it should save the data as clean data and also return \n",
    "- duplicates records, clean_data \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da1f0382-2c53-4e3e-9bf5-49d0202fdf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import openpyxl\n",
    "import xlrd\n",
    "import os\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fa5aa818-4099-4bc5-8969-e66a6876d230",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_path ='sales.xlsx'\n",
    "#data_name ='jan_sales'\n",
    "\n",
    "\n",
    "def data_cleaning_master(path, data_name):\n",
    "    \n",
    "    print(\"Thank you for giving the details!\")\n",
    "    sec=random.randint(1,4) #generating random number\n",
    "\n",
    "    #print delay message\n",
    "    print(f\"Please wait for {sec} seconds! Checking file path\")\n",
    "    time.sleep(sec)\n",
    "\n",
    "    \n",
    "    # checking if path exists\n",
    "    if not os.path.exists(data_path):\n",
    "        print(\"Incorrect path! Try again with correct path\")\n",
    "        return\n",
    "    else:\n",
    "        # Checking the file type\n",
    "        if data_path.endswith('.csv'):\n",
    "            print(\"Dataset is CSV!\")\n",
    "            data=pd.read_csv(data_path, encoding_errors='ignore')\n",
    "    \n",
    "        \n",
    "        elif data_path.endswith('.xlsx'):\n",
    "            print(\"Dataset is excel file!\")\n",
    "            data=pd.read_excel(data_path)\n",
    "        else:\n",
    "            print(\"Unknown File time\")\n",
    "            return\n",
    "    \n",
    "    #print delay message\n",
    "    sec=random.randint(1,4)\n",
    "    print(f\"Please wait for {sec} seconds! Checking total rows and columns\")\n",
    "    time.sleep(sec)\n",
    "     \n",
    "    #showing number of records\n",
    "    print(f\"Dataset contains total rows: {data.shape[0]}\\n Total Columns: {data.shape[1]}\")\n",
    "    \n",
    "    # start cleaning\n",
    "    \n",
    "    #print delay message\n",
    "    sec=random.randint(1,4)\n",
    "    print(f\"Please wait for {sec} seconds! Checking total Duplicates\")\n",
    "    time.sleep(sec)\n",
    "    \n",
    "    #checking duplicates\n",
    "    duplicates = data.duplicated()\n",
    "    total_duplicate = data.duplicated().sum()\n",
    "    print(f'dataset has total duplicates records: {total_duplicate}')\n",
    "\n",
    "    #print delay message\n",
    "    sec=random.randint(1,4)\n",
    "    print(f\"Please wait for {sec} seconds! saving total duplicate rows\")\n",
    "    time.sleep(sec)\n",
    "    \n",
    "    #saving the duplicates\n",
    "    if total_duplicate>0:\n",
    "        duplicate_records = data[duplicates]\n",
    "        duplicate_records.to_csv(f'{data_name}_duplicates.csv', index=None)\n",
    "    \n",
    "    #deleting duplicates\n",
    "    df = data.drop_duplicates()\n",
    "    \n",
    "    #print delay message\n",
    "    sec=random.randint(1,10)\n",
    "    print(f\"Please wait for {sec} seconds! Checking for missing values\")\n",
    "    time.sleep(sec)\n",
    "    \n",
    "    # find missing values\n",
    "    total_missing_value =  df.isnull().sum().sum()\n",
    "    missing_values_by_columns = df.isnull().sum()\n",
    "    \n",
    "    print(f'Dataset have total missing value: {total_missing_value}')\n",
    "    print(f'Dataset contains missing value by columns \\n {missing_values_by_columns}')\n",
    "    \n",
    "    #dealing with missing values\n",
    "    #fillna -- int/float\n",
    "    #dropna -- any object type\n",
    "\n",
    "    #print delay message\n",
    "    sec=random.randint(1,4)\n",
    "    print(f\"Please wait for {sec} seconds! Cleaning the datasets\")\n",
    "    time.sleep(sec)\n",
    "    \n",
    "    columns=df.columns\n",
    "    \n",
    "    for col in columns:\n",
    "        # filling mean for numeric columns all rows\n",
    "        if df[col].dtype in (int, float):\n",
    "            df[col]=df[col].fillna(df[col].mean())\n",
    "        else:\n",
    "            #dropping all rows with missing records for nonnumber col\n",
    "            df.dropna(subset=col, inplace =True)\n",
    "    \n",
    "    \n",
    "    #print delay message\n",
    "    sec=random.randint(1,4)\n",
    "    print(f\"Please wait for {sec} seconds! Exporting datasets\")\n",
    "    time.sleep(sec)\n",
    "    \n",
    "    # dats is cleaned\n",
    "    print(f\"Congrats! Datasetis cleaned! Number of rows: {df.shape[0]} Number of columns: {df.shape[1]}\")\n",
    "    \n",
    "    #saving the cleaned dataset\n",
    "    df.to_csv(f'{data_name}_Clean_data.csv', index=None)\n",
    "    print(\"Dataset is  Saved!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3bb927c3-7447-437c-9894-aa57b97f36b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcoming to data cleaning master\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter dataset path:  sales.xlsx\n",
      "Please enter dataset name:  ibm sales\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for giving the details!\n",
      "Please wait for 3 seconds! Checking file path\n",
      "Dataset is excel file!\n",
      "Please wait for 3 seconds! Checking total rows and columns\n",
      "Dataset contains total rows: 24\n",
      " Total Columns: 10\n",
      "Please wait for 3 seconds! Checking total Duplicates\n",
      "dataset has total duplicates records: 4\n",
      "Please wait for 3 seconds! saving total duplicate rows\n",
      "Please wait for 3 seconds! Checking for missing values\n",
      "Dataset have total missing value: 17\n",
      "Dataset contains missing value by columns \n",
      " Sales_ID          2\n",
      "Product           2\n",
      "Price             2\n",
      "Quantity          3\n",
      "Customer_ID       1\n",
      "Order_Date        2\n",
      "City              2\n",
      "Sales_Rep         0\n",
      "Discount          2\n",
      "Payment_Method    1\n",
      "dtype: int64\n",
      "Please wait for 3 seconds! Cleaning the datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\AppData\\Local\\Temp\\ipykernel_8448\\1496798332.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col]=df[col].fillna(df[col].mean())\n",
      "C:\\Users\\abhis\\AppData\\Local\\Temp\\ipykernel_8448\\1496798332.py:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.dropna(subset=col, inplace =True)\n",
      "C:\\Users\\abhis\\AppData\\Local\\Temp\\ipykernel_8448\\1496798332.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col]=df[col].fillna(df[col].mean())\n",
      "C:\\Users\\abhis\\AppData\\Local\\Temp\\ipykernel_8448\\1496798332.py:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.dropna(subset=col, inplace =True)\n",
      "C:\\Users\\abhis\\AppData\\Local\\Temp\\ipykernel_8448\\1496798332.py:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.dropna(subset=col, inplace =True)\n",
      "C:\\Users\\abhis\\AppData\\Local\\Temp\\ipykernel_8448\\1496798332.py:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.dropna(subset=col, inplace =True)\n",
      "C:\\Users\\abhis\\AppData\\Local\\Temp\\ipykernel_8448\\1496798332.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col]=df[col].fillna(df[col].mean())\n",
      "C:\\Users\\abhis\\AppData\\Local\\Temp\\ipykernel_8448\\1496798332.py:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.dropna(subset=col, inplace =True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait for 3 seconds! Exporting datasets\n",
      "Congrats! Datasetis cleaned! Number of rows: 15 Number of columns: 10\n",
      "Dataset is  Saved!\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "\n",
    "    print(\"Welcoming to data cleaning master\")\n",
    "    # ask the path and file name\n",
    "    data_path = input(\"Please enter dataset path: \")\n",
    "    data_name = input(\"Please enter dataset name: \")\n",
    "\n",
    "    #calling functions\n",
    "    data_cleaning_master(data_path, data_name)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "646152e0-a49b-4b6f-ba63-30ff8b643f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook main.ipynb to script\n",
      "[NbConvertApp] Writing 4311 bytes to main.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script main.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7520996b-0030-4fb9-bfc2-fca3111699d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
